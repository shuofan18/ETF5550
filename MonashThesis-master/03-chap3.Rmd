---
chapter: 3
knit: "bookdown::render_book"
---


# Comparison with Turk studies

A large database of results from a human subjects test conducted to validate the lineup protocol relative to a classical tests is going to be used for this part of the work. This data was collected as part of the work presented in @MM13. Experiment 2 examined the performance of humans in recognising linear association between two variables, in direct comparison to conducting a $t$-test of $H_o: \beta_k=0$ vs $H_a: \beta_k\neq 0$ assessing the importance of including variable $k$ in the linear model. An example lineup is shown in Figure \ref{expt2}. For this lineup, 63 of the 65 people who examined it selected the data plot (position 20) from the null plots. There is clear evidence that the data displayed in plot 20 is not from $H_o: \beta_k=0$. 

\begin{figure*}[h]
\centerline{\includegraphics[width=15cm]{figures/plot_turk2_300_350_12_3.png}}
\caption{One of 70 lineups used in experiment 2 Majumder et al (2012). Of the 65 people who examined the lineup,  63 selected the data plot, which is in position 20.}
\label{expt2}
\end{figure*}



This experiment utilised 70 lineups of size 20 plot, with varying degrees of departure from the $H_o: \beta_k=0$. There were 351 evaluations by human subjects. These results will be used for comparison with the deep learning model. 

The trained deep learning model will be applied to the data from this experiment. The model will be asked classify each plot in each lineup. We will calculate how frequently the data plot is selected as not a null plot, and compare this to the frequencies obtained by human evaluation. 

## Classify samples using our model

<!--
After first training attempt with 20,000 observations (15,000 linear and 5,000 no-relationship), the model's performance is shown below. The accuracy tested on unseen data is roughly 89.7%, where the test data is generated from the same specification with training data.
-->

```{r history, echo=FALSE}

#load png

```





## Compare accuracy of computer vs human reading

We first try to use the model classify the real plots directly. The accuracy is roughly 42% for the 70 real data plots. We think this result is reasonable since the averaged power of the conventional t-test of these 70 plots is calculated as 0.4567.

Next we will let the model select the highest probability of being linear within each 20 plots, as the same with what human do in the experiment 2.




























